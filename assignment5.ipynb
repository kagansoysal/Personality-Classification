{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bdbaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Normalization;\n",
      "    for k = 1 \t Accuracy = ½99.46066454971128 | Precision = ½95.83790109569188 | Recall = ½95.83041526893138\n",
      "    for k = 3 \t Accuracy = ½99.63135869752908 | Precision = ½97.12503609852024 | Recall = ½97.1143952269601\n",
      "    for k = 5 \t Accuracy = ½99.67834628246685 | Precision = ½97.4805510017144 | Recall = ½97.47482957875332\n",
      "    for k = 7 \t Accuracy = ½99.69031725882964 | Precision = ½97.5768073830037 | Recall = ½97.56518690013897\n",
      "    for k = 9 \t Accuracy = ½99.70660497889116 | Precision = ½97.69901394187413 | Recall = ½97.69169067032274\n",
      "\n",
      "  Total Accuracy = ½97.24828747145786\n",
      "\n",
      "\n",
      "\n",
      "With Normalization;\n",
      "    for k = 1 \t Accuracy = ½99.7152896663001 | Precision = ½97.76429699099616 | Recall = ½97.76253236130182\n",
      "    for k = 3 \t Accuracy = ½99.82603848118885 | Precision = ½98.6243851446648 | Recall = ½98.62301420476894\n",
      "    for k = 5 \t Accuracy = ½99.8494767609813 | Precision = ½98.80788956371268 | Recall = ½98.80622867768119\n",
      "    for k = 7 \t Accuracy = ½99.85266859468948 | Precision = ½98.83339843337203 | Recall = ½98.83153559942429\n",
      "    for k = 9 \t Accuracy = ½99.85904566770725 | Precision = ½98.88209399207126 | Recall = ½98.88191746719424\n",
      "\n",
      "  Total Accuracy = ½98.58897648294138\n"
     ]
    }
   ],
   "source": [
    "# Gazi Kağan Soysal - 2210356050 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"16P.csv\", encoding=\"ISO-8859-1\")\n",
    "df.drop([\"Response Id\"], inplace=True, axis=1)\n",
    "df_without_normalization = pd.DataFrame(df)\n",
    "df.replace([-3, -2, -1, 0, 1, 2, 3], [0, 1/6, 2/6, 3/6, 4/6, 5/6, 1], inplace=True) # We are applying normalization to one of our DataFrames\n",
    "personalities = [\"ESTJ\", \"ENTJ\", \"ESFJ\", \"ENFJ\", \"ISTJ\", \"ISFJ\", \"INTJ\", \"INFJ\", \"ESTP\", \"ESFP\", \"ENTP\", \"ENFP\", \"ISTP\",\n",
    "                 \"ISFP\", \"INTP\", \"INFP\"]\n",
    "df_without_normalization.replace(personalities, range(16), inplace=True)\n",
    "df.replace(personalities, range(16), inplace=True)\n",
    "performance = {}\n",
    "(int1, int2, int3, int4, int5, int6) = (0, 12000, 24000, 36000, 48000, 59999)\n",
    "intervals = list(zip((int1, int2, int3, int4, int5), (int2, int3, int4, int5, int6))) # Since we will divide our test by 5, we create our intervals\n",
    "number_true = 0\n",
    "number_false = 0\n",
    "\n",
    "def k_fold_cross_validation(k_value, interval):\n",
    "    global number_true, number_false\n",
    "\n",
    "    metrics = [\"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "    for personality in personalities: # We create this dictionary to hold the metric values for each class\n",
    "        performance[personality] = {}\n",
    "        for character in performance:\n",
    "            for metric in metrics:\n",
    "                performance[character][metric] = 0 #\n",
    "    for test_person in range(interval[0], interval[1]):\n",
    "        test_sample = datas[test_person, :-1]\n",
    "        train_samples = np.concatenate((datas[:interval[0], :-1], datas[interval[1]:int6, :-1]))\n",
    "        substraction = test_sample - train_samples\n",
    "        squared_substraction = substraction ** 2\n",
    "        sum_squared_substraction = np.sum(squared_substraction, axis=1)\n",
    "        distances = sum_squared_substraction ** (1 / 2) # We calculated the distances\n",
    "        train_interval = list(range(interval[0])) + list(range(interval[1], int6))\n",
    "        dict_distances = dict(zip(distances, train_interval)) # We matched which distance belongs to which player.\n",
    "        distances.sort()\n",
    "        nearest_neighbors = [dict_distances[distances[k]] for k in range(k_value)]\n",
    "        nearest_personalities = [datas[index, -1] for index in nearest_neighbors]\n",
    "        most = max(set(nearest_personalities), key=nearest_personalities.count) # According to the k value given, we estimated which personality has the most among the nearest neighbors for the test person.\n",
    "\n",
    "        # In the following part, we calculate the metric values for each class\n",
    "        if most == datas[test_person, -1]:\n",
    "            number_true += 1\n",
    "            performance[personalities[int(datas[test_person, -1])]][\"TP\"] += 1\n",
    "            for personality in performance:\n",
    "                if personality == personalities[int(datas[test_person, -1])]:\n",
    "                    continue\n",
    "                else:\n",
    "                    performance[personality][\"TN\"] += 1\n",
    "        else:\n",
    "            number_false += 1\n",
    "            performance[personalities[int(datas[test_person, -1])]][\"FN\"] += 1  # FN\n",
    "            performance[personalities[int(most)]][\"FP\"] += 1  # FP\n",
    "\n",
    "# In this function, we are testing for each value of k and each fold. Then we calculate the \"Accuracy, Precision and Recall\" ratios for each.\n",
    "def loop():\n",
    "    for k in [1, 3, 5, 7, 9]:\n",
    "        accuracy, precision, recall = 0, 0, 0\n",
    "        for i in intervals:\n",
    "            k_fold_cross_validation(k, i)\n",
    "        for personality in performance:\n",
    "            accuracy += (performance[personality][\"TP\"] + performance[personality][\"TN\"]) / (performance[personality][\"TP\"] + performance[personality][\"FP\"] + performance[personality][\"TN\"] + performance[personality][\"FN\"])\n",
    "            precision += performance[personality][\"TP\"] / (performance[personality][\"TP\"] + performance[personality][\"FP\"])\n",
    "            recall += performance[personality][\"TP\"] / (performance[personality][\"TP\"] + performance[personality][\"FN\"])\n",
    "        print(f\"    for k = {k} \\t Accuracy = ½{100 * accuracy / 16} | Precision = ½{100 * precision / 16} | Recall = ½{100 * recall / 16}\")\n",
    "    print(f\"\\n  Total Accuracy = ½{100 * number_true / (number_true + number_false)}\")\n",
    "\n",
    "# We run our test first without normalization and then with normalization.\n",
    "print(\"Without Normalization;\")\n",
    "datas = np.array([df_without_normalization.loc[data] for data in range(59999)])\n",
    "loop()\n",
    "\n",
    "number_true, number_false = 0, 0\n",
    "print(\"\\n\\n\\nWith Normalization;\")\n",
    "datas = np.array([df.loc[data] for data in range(59999)])\n",
    "loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2860842",
   "metadata": {},
   "source": [
    "# Error Analysis for Classification\n",
    "\n",
    "    > Our test cannot predict all results correctly. I think it's because the person we're testing has the same distances as more than one person. In such a situation, our code looks at the first person with the distance it is looking for in the dictionary, and does not look at other people. This causes an incorrect prediction.\n",
    "\n",
    "    > As the k value in the k-NN algorithm increases, we see that the \"Accuracy, Presicion and Recall\" values ​​in our code increase.\n",
    "    \n",
    "    > When we apply normalization to our code, we see that the \"Accuracy, Precision, Recall\" values ​​increase again. The reason for this is that the sensitivity ratio increases as the values ​​get closer to each other.\n",
    "    \n",
    "    > In our code, we apply the test in the form of 5 folds. If the number of folds increases, the accuracy rate will increase as the number of people we compare the person we test will increase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
